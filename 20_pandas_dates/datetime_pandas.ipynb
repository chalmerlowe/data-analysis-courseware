{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "Datetimes in pandas\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's start by importing the pertinent libraries and functions\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date objects\n",
    "\n",
    "Before we go into anything `pandas` specific let's talk a little bit about the built-in library `datetime`. With it we can create datetime objects which `pandas` can use for some really cool things. Keep in mind this is a `datetime` **object** NOT a **string** that looks like a date. These `datetime` objects have attributes and behaviors we can examine and call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "date1 = datetime(2016, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The printed display looks like a string\n",
    "print('str display:', date1)\n",
    "\n",
    "# But the item is an actual object \n",
    "print('object type: ', type(date1))\n",
    "\n",
    "# The object itself:\n",
    "date1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our datetime object tells us that it can potentially store more than just the year, month, and day. We see two zeroes we didn't define so there must be something that can go there. Let's turn to the help documentation to see if we figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datetime?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we learn that the datetime object can also hold data representing:\n",
    "\n",
    "* hours\n",
    "* minutes\n",
    "* seconds\n",
    "* microseconds\n",
    "* time zones\n",
    "\n",
    "Let's take a look at the difference between two datetime objects. Let's make two dates but one has the hour value set to **12** and one has the hour value set to **11**. Let's see the time difference between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date2 = datetime(2016, 5, 3, 12)\n",
    "date3 = datetime(2016, 5, 3, 11)\n",
    "\n",
    "difference = date2 - date3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take a look at this difference object\n",
    "print('str display:', difference)\n",
    "\n",
    "print('object type: ', type(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But let's look at the object itself\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of us were probably expecting something like \"1 hour\" but instead we got \"3600 something\". Let's try looking at the help for a timedelta and see what we can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timedelta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that wasn't what we really expected either. Let's try using IPython's verbose help (You can get to it with the double question marks: **??**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timedelta??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verbose help shows us the source code AND in this case, we can see some additional details the author included... such as a snarky comment on what we just saw\n",
    "\n",
    "\n",
    "Any category of time that does not fit one of these three categories:\n",
    "\n",
    "* Days\n",
    "* Seconds\n",
    "* Microseconds\n",
    "\n",
    "Gets converted to the closest lower category. The hour got converted to 3600 seconds\n",
    "\n",
    "As an object if we want access to individual time categories we can use **dot notation** to access the attributes for the datetime and timedelta objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(difference.days)\n",
    "print(difference.seconds)\n",
    "\n",
    "# Want to see the other attributes and methods?\n",
    "# difference.<tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similarly, we can see the attributes for one of our\n",
    "# previous date objects:\n",
    "print(date3.hour)\n",
    "print(date3.day)\n",
    "print(date3.month)\n",
    "print(date3.year)\n",
    "\n",
    "# Want to see the other attributes and methods?\n",
    "# date3.<tab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datetime objects have a:\n",
    "\n",
    "* default string representation\n",
    "* an ISO representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default string format:\n",
    "print(str(date3))\n",
    "\n",
    "# ISO format:\n",
    "print(date3.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the `datetime` module has the ability to both read in values and write out values using **user defined** formats.\n",
    "\n",
    "`*.strftime()`\n",
    "\n",
    "`*.strptime()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# string formatting:\n",
    "To format the `str` output of a `datetime` object to suit your needs, you can use `strftime()` and can mix and match from the formatting specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datef = datetime(2009, 9, 9)\n",
    "datef.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not gonna go into the full collection of formatting specifications.\n",
    "\n",
    "That is left as an exercise for the student:\n",
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "### WARNING:\n",
    "\n",
    "I have not confirmed this, but I have heard that the supported formatting codes vary across platforms (linux, unix, windows, mac, etc) because Python relies upon the underlying C library's strftime() function.\n",
    "\n",
    "Purportedly, the Python Docs reflect all the formatting codes from the 1989 version of the C standard which **should be consistent across all platforms**\n",
    "\n",
    "But some libraries may implement **additional** formatting codes.\n",
    "\n",
    "hattip to Will McCutchen's site: http://strftime.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# string parsing:\n",
    "Sometimes we get strings that contain dates but have unusual formatting. You can parse the string manually and convert it to a datetime object with the `strptime()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Presume that we have the following string that is a month, day and year separated\n",
    "# by '|' symbols.\n",
    "datep = '8|8|2008'\n",
    "datetime.strptime(datep, '%m|%d|%Y')\n",
    "\n",
    "# In deference to time, we are gonna leave a deep dive into the\n",
    "# formatting specifications for the student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While manually setting the formatting works, for heavy duty datetime parsing, the automagic parsing available via the dateutil module is hard to beat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01                          2000-01-01 00:00:00\n",
      "December 12, 2001 13:13             2001-12-12 13:13:00\n",
      "23rd January 2002 21:21:21          2002-01-23 21:21:21\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "d1 = '2000-01-01'\n",
    "d2 = 'December 12, 2001 13:13'\n",
    "d3 = '23rd January 2002 21:21:21'\n",
    "\n",
    "for dateobject in d1, d2, d3:\n",
    "    print(dateobject.ljust(35), parse(dateobject))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2001, 10, 12, 13, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse('12 OCT 2001 13:13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `datetime` module:\n",
    "\n",
    "* create a `datetime` of the day of your birth\n",
    "* create a `datetime` of today **including** the current time\n",
    "* calculate the difference between them\n",
    "\n",
    "Once you've done that \n",
    "\n",
    "* make another `datetime` of your most RECENT birthday\n",
    "* calculate the difference between it and today\n",
    "* calculate how many hours are represented by the seconds (hint: divide the number of seconds by 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you complete this exercise, please put your green post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pandas`\n",
    "As much as it may seem like it, this talk is NOT intended to cover just the `datetime` or `dateutil` modules... but we need to cover them to give us perspective on what `pandas` can do.\n",
    "\n",
    "Let's start by reading in a csv. We:\n",
    "* read in the csv\n",
    "* provide a list of column names\n",
    "* identify a column for use as an index\n",
    "* tell `pandas` to automagically parse the strings into dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('log_file.csv', names=['name', 'email',\n",
    "                                        'fmip', 'toip',\n",
    "                                        'datetime', 'lat',\n",
    "                                        'long', 'payload'],\n",
    "                                 index_col='datetime',\n",
    "                                 parse_dates=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, let's assign a label to the data held in the name column to simplify the task of referencing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = df['name']\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`names` is a `Series` and like any `Series`, it has an **`index`**. We can provide a label for the index as a separate entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = names.index\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like any index... we can select for individual entities from the index using indexing and slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within pandas, you can index using the integer count (as we saw above) *OR* using a string representation of a specific timestamp.\n",
    "\n",
    "One of the powerful aspects of selection based on index is that you can select items from the `index`, from a `Series`, or from an entire `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time = '2016-02-06 21:47:02'\n",
    "names[time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching against a substring from within a longer string is possible as well. Here, let's match against any item in the `Series` with the substring '2016-02-06' in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names['2016-02-06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next trick, let's use a new DataFrame and Series from a longer dataset (~1000 records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1000 = pd.read_csv('log_file_1000.csv', names=['name', 'email',\n",
    "                                                  'fmip', 'toip',\n",
    "                                                  'datetime', 'lat',\n",
    "                                                  'long', 'payload'],\n",
    "                                                 index_col='datetime',\n",
    "                                                 parse_dates=True)\n",
    "\n",
    "names_long = df_1000['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: many of the most common interpretations of a 'date and time', even if they are NOT a letter-for-letter match of the string will work for selecting dates.\n",
    "\n",
    "This first item will bring back 740+ records that have 2015 in the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nl = names_long['2015']\n",
    "nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_long['September 2015']      # <--- yields ~ 181 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_long['31st Oct, 2015']       #  <--- yields ~ 9 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the datetime information in the DataFrame/Series is in chronological order you can use slice syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_long['Oct, 29 2015':'Oct, 31 2015']         # <--- yields ~ 28 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are gonna ingest a dataset, but we will apply a function to truncate the datetime string to only represent the date.\n",
    "\n",
    "We define a simple function to split the datetime strings into dates and times, and retain only the dates. `pandas` allows us to apply the function when we read in the data using the 'converters' argument of the `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_split(dt):\n",
    "    return dt.split('T')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_long = pd.read_csv('log_file_1000.csv', names=['name', 'email',\n",
    "                                                   'fmip', 'toip', \n",
    "                                                   'datetime', 'lat',\n",
    "                                                   'long', 'payload'],\n",
    "                      index_col='datetime',\n",
    "                      converters={'datetime':date_split},\n",
    "                      parse_dates=True)\n",
    "\n",
    "df2_long[['name', 'lat', 'long', 'payload']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new dataset, we can see many dates that duplicate or repeat, which means that we have the capability to group by those dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df2_long.name.groupby(level=0)  # groupby the zeroeth\n",
    "                                          # level of the index \n",
    "                                          # hierarchy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let's quickly check the size of the groups...\n",
    "\n",
    "grouped.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read in the same data set (`log_file_1000.csv`) as a `pandas DataFrame`\n",
    "* Create separate `DataFrame` that only includes rows between the\n",
    "    * 29th of December 2015\n",
    "    * 5th of January 2016\n",
    "    \n",
    "* Confirm that your `DataFrame` only contains the dates that you want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you complete this exercise, please put your green post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_long = pd.read_csv('log_file_1000.csv', names=['name', 'email',\n",
    "                                                   'fmip', 'toip', \n",
    "                                                   'datetime', 'lat',\n",
    "                                                   'long', 'payload'],\n",
    "                      index_col='datetime',\n",
    "                      converters={'datetime':date_split},\n",
    "                      parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occasionally, our time series doesn't have all the periods\n",
    "# that we might want... resampling can solve that problem.\n",
    "# Similarly, sometimes our time series might have too many samples\n",
    "\n",
    "df2_long.resample('4h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_long = pd.read_csv('log_file_1000.csv', names=['name', 'email',\n",
    "                                                   'fmip', 'toip', \n",
    "                                                   'datetime', 'lat',\n",
    "                                                   'long', 'payload'],\n",
    "                      index_col='datetime',\n",
    "                      converters={'datetime':date_split},\n",
    "                      parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When resampling, by default, pandas applies the mean if\n",
    "# that processing makes sense.... \n",
    "# We will also see other ways of handling resampling.\n",
    "\n",
    "\n",
    "df2_long.resample('2D').sum()\n",
    "\n",
    "# try:\n",
    "# .var()\n",
    "# .std()\n",
    "# etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Frequencies are defined as a base frequency and a multiplier...\n",
    "#   2M - every two months\n",
    "#   2h30min - every two hours, 30 mins\n",
    "#   D - daily\n",
    "#   B - business daily\n",
    "\n",
    "#   BM - End of the business month\n",
    "\n",
    "#   W-MON - weekly on a given day of the week\n",
    "#   WOM-1TUE - week of the month(1st, 2nd, etc) and day of week\n",
    "#   QS-JAN - start of the quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, knowing how to handle Time Zones is important... especially in ensuring accuracy across time zones. Let's take just the first 10 lines of the column `name` in the long file. At this moment, there is no explicit time zone associated with these time stamps. This is referred to as time zone naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = df_1000.name[:10]\n",
    "print(times.index.tz)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To translate from naive to a specific timezone, we use the localize function. Common practice is to define the 'local' timezone using the standard name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_est = times.tz_localize('US/Eastern')\n",
    "print(times.index.tz)\n",
    "times_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you set the local timezone for a TimeSeries, you can convert it to align to other time zones. In this case, we see that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_hi = times_est.tz_convert('US/Hawaii')\n",
    "times_hi\n",
    "\n",
    "# February is during that window when the\n",
    "#     HI <-> EST offset is five hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinations between two different timezones will result in an output normalized to UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, we have dealt predominantly with potentially irregularly timestamped data. One of the other main classes of timing data is periodic time spans such as years, months, minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "period = pd.Period(2015, freq='W-MON')\n",
    "period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This period represents a single time span across one week at the end of 2014/beginning of 2015, starting on a Mon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a sequence or range of periods, you can use the `period_range()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_range = pd.period_range('12/12/2010', '12/12/2015', freq='Q')\n",
    "per_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a Period to a different frequency, you can use the *.asfreq() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "period.asfreq('W', how='start')\n",
    "\n",
    "# the default starting day is Sun, but this is configurable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly convert whole sequences of periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_range.asfreq('D', how='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_period = df_1000.to_period('M')\n",
    "df_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert back to timestamps...\n",
    "\n",
    "The day of the month data gets lost in the above conversion, so pandas resorts to a default of the first day of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ts = df_period.to_timestamp(how='start')\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once resampled we can use different methods to display our data... Remember mean is default but we can use others\n",
    "\n",
    "Use the resample method then use the method you want on it after the fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1000[['lat', 'long']].resample('Q', kind='period').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methods you can use:\n",
    "* mean\n",
    "* median\n",
    "* std\n",
    "* first\n",
    "* last\n",
    "* min\n",
    "* max\n",
    "* var\n",
    "* count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a wrap-up, let's take a look at plotting some of this data. (For more examples of plotting, one of our earlier demo scripts has a variety of sample plots. Also, matplotlib has an extensive library of sample plots).\n",
    "\n",
    "We'll start with setting up the interactive environment so we an manipulate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From there, we create a reduced dataset and create a subplot that is two rows\n",
    "# high, one column wide and we activate the first subplot. Then we set up the\n",
    "# graph for that subplot to display the latitude in black circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1000 = df_1000[['lat', 'long']][:750]\n",
    "plt.subplot(2, 1, 1)\n",
    "df_1000['lat'].plot(style='ko')\n",
    "\n",
    "\n",
    "# Next we activate the second subplot and set up the graph for that subplot to\n",
    "# display the longitude in\n",
    "plt.subplot(2, 1, 2)\n",
    "df_1000['long'].plot(style='b^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
