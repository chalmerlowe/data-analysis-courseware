{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "Gathering data from the web\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Use and understand the basics of the `urllib` module\n",
    "* Use and understand the basics of the `beautiful soup` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this session, we want to cover several issues related to network communications, so that folks have a better sense of what happens when a request to website happens. We will not go into any depth, this is predominantly to ensure that we are on the same page in terms of vocabulary, etc.\n",
    "\n",
    "We'll cover the Transmission Control Protocol (TCP), port numbers used by that protocol and the Hypertext Transfer Protocol (HTTP). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission Control Protocol (TCP)\n",
    "\n",
    "TCP is a protocol that is commonly used to send data across a network. The protocol is based on a standard published by the Internet Engineering Task Force and can be [found here](https://tools.ietf.org/html/rfc793). TCP is one component of the TCP/IP stack:\n",
    "\n",
    "|Layer|Example technologies at each layer (not all-inclusive)|\n",
    "|:---||\n",
    "|Application|Browser, FTP, email, telnet communications|\n",
    "|Transport|TCP, UDP port numbers|\n",
    "|Internet|IP address|\n",
    "|Network|MAC address|\n",
    "\n",
    "TCP has these general properties (not an all-inclusive list):\n",
    "\n",
    "* Relies upon some builtin mechanisms to help increase reliability (error checking, etc)\n",
    "* Creates connections between two devices (it is referred to as a connection-oriented protocol)\n",
    "* Uses checks to ensure that all data has been correctly received, if not, it can request that missing data be resent\n",
    "* Uses sequence numbering to ensure that packets can be put into a specific order\n",
    "* Between the reliability checks and the organization/ordering of packets, it is very effective for the sending files (like web pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port numbers\n",
    "\n",
    "The TCP protocol incorporates the use of port numbers:\n",
    "\n",
    "* Any given computer may have multiple pieces of software running that are willing to accept incoming traffic\n",
    "* Each of these applications will request that the computer listen on a specific port number (or numbers)\n",
    "* When the computer receives traffic destined to a specific port, it will direct that traffic to the right application.\n",
    "* Multiple open ports allows multiple applications on the same computer to talk without interfering with each other\n",
    "* Historically certain applications have default TCP port numbers that are used to send higher-level protocols\n",
    "* There are over ~65,000 ports\n",
    "* Ports between 0 and 1023 are referred to as **well-known ports**\n",
    "* Ports between 1024 and 49151 are the **registered ports**. They are assigned by the Internet Assigned Numbers Authority (IANA)\n",
    "* Ports between 49152 and 65535 are referred to as **ephemeral ports** and are often opened as needed to allow the computer to assign a source port number for any TCP packets that is sends outside the bounds of an established protocol.\n",
    "\n",
    "Task | Port\n",
    ":----|:----\n",
    "Telnet | 23\n",
    "SSH | 22\n",
    "HTTP | 80\n",
    "HTTPS | 443\n",
    "SMTP (E-mail) | 25\n",
    "DNS (Domain Name) | 53\n",
    "FTP (File Transfer) | 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertext Transfer Protocol (HTTP)\n",
    "\n",
    "HTTP is one of many common protocols that may be sent using TCP.\n",
    "\n",
    "* HTTP is the standard Protocol for most web applications on the Internet\n",
    "* Invented to retrieve HTML, images, Documents, etc.\n",
    "* Basic concept:\n",
    "    * Make a connection\n",
    "    * Request a document\n",
    "    * Retrieve the document and display it\n",
    "    * Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP uses Uniform Resource Locators (URL) to identify device addresses. A URL address has several components:\n",
    "\n",
    "* The URL indicates the protocol, generally HTTP (but it could be others)\n",
    "* It lists the host (server) that hosts the document\n",
    "* The name and path to the specific document\n",
    "\n",
    "http://  | www.example.com/ | index.html\n",
    ":--------|:-------------|:----------------\n",
    "Protocol | Host         | Document\n",
    "\n",
    "\n",
    "http://  | localhost:8000/ | index.html\n",
    ":--------|:-------------|:----------------\n",
    "Protocol | Host:Port         | Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this URL fit into the scheme of things?\n",
    "\n",
    "* Browser attempts to connect to `http://www.example.com`\n",
    "    * if no port is given, then it attempts to connect on port 80\n",
    "    * if a port is given, then it attempts to connect on that port number\n",
    "* It issues a request for a document called `index.html`\n",
    "* The server responds and sends the html document\n",
    "* Browser renders the html document\n",
    "* Browser closes the connection when it is no longer needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP requests in Python using urllib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to import the request module from the urllib package\n",
    "\n",
    "This package has several modules, including the urllib.request module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported a new module that we have never used, we should explore it. Try to find out what functions and attributes are present, using `urllib.request.<tab complete>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# urllib allows us to open web pages just like opening files by using the *.urlopen() method.\n",
    "# The following command creates an http.client.HTTPResponse object that\n",
    "#     gives us access to a number of attributes and behaviors\n",
    "#     related to the data retrieved\n",
    "\n",
    "file = urllib.request.urlopen('http://www.gutenberg.org/cache/epub/11757/pg11757.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's take a look at this object we created called `file`, again using `file.<tab complete>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A common technique is to use a for loop to cycle through every\n",
    "# line and print out the data one line at a time\n",
    "# In this case, the data is read in as BYTES instead of as a STRING.\n",
    "#     which will require us to call the decode method on each line.\n",
    "\n",
    "for line in file:\n",
    "    # We convert each line from bytes to strings using the\n",
    "    #     .decode() attribute.\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Much like other files we have looked at, we can \n",
    "# read and evaluate the text in web-based text files, \n",
    "# i.e. we can do tasks like counting words\n",
    "\n",
    "file = urllib.request.urlopen('http://www.gutenberg.org/cache/epub/11757/pg11757.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = {}\n",
    "\n",
    "for line in file:\n",
    "    \n",
    "    # Again, we take the line and use .decode() to convert\n",
    "    #     the data to a string\n",
    "    #     Then we strip the newline\n",
    "    #     Then we split it on spaces\n",
    "    words = line.decode().strip().split()\n",
    "    \n",
    "    # We cycle through the words one at a time\n",
    "    for word in words:\n",
    "        \n",
    "        # If a key for the word already exists .get() grabs the value otherwise it automatically returns 0\n",
    "        count[word] = count.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode and Python text\n",
    "\n",
    "* Internally, within Python 3+, all Python strings are Unicode\n",
    "* When we talk to a network we usually have to encode and decode our data (generally to `utf-8`)\n",
    "* When we receive data from a web server, we typically recieve it as a `bytes` object which we then pass through a `.decode()` method to get a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor man debugging...\n",
    "# I find this to be one of the most useful lines of code to a \n",
    "#     new Pythonista\n",
    "\n",
    "print(type(line), line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the difference between outputting:\n",
    "#     a bytes object vs.\n",
    "#     a string\n",
    "\n",
    "print(line)\n",
    "clean_line = line.decode()\n",
    "\n",
    "print(type(clean_line), clean_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading web pages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our earlier examples were fairly straightforward, since we \n",
    "#     retrieved text files. Most of the web is not \n",
    "#     straight text files, it is composed of \n",
    "#     Hyper Text Markup Language (HTML)\n",
    "\n",
    "# We request a page using urllib.request.urlopen()\n",
    "\n",
    "page = urllib.request.urlopen('http://www.example.com/index.html')\n",
    "\n",
    "for line in page:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful soup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to use `urllib` to read data from the web, a third party library, `Beautiful Soup` is commonly used instead to supplement urllib. `Beautiful Soup`:\n",
    "\n",
    "* Makes reading and parsing web pages a lot easier\n",
    "* Allows you to extract tags of only certain types\n",
    "* You can find certain tags based on their relationship in the tag heirarchy\n",
    "* Getting hyperlinks becomes a whole lot easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the command line\n",
    "\n",
    "If you want to install Beautiful Soup, on your own system:\n",
    "\n",
    "Make sure you activate your desired conda virtual environment\n",
    "And use `conda` to install Beautiful Soup in that environment\n",
    "\n",
    "```bash\n",
    "$ conda activate myenv\n",
    "(myenv)$ conda install beautifulsoup4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the html text from the HTTPResponse object\n",
    "# Notice the .read() method that we daisy chained on the end.\n",
    "# What are pros and cons of this approach?\n",
    "\n",
    "htmlText = urllib.request.urlopen('http://www.unicode.org/').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(htmlText), htmlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use bs4 to create a soup object from our html text\n",
    "# Provide an argument to identify which type of parser to\n",
    "#     use, in this case, an html parser\n",
    "\n",
    "soup = BeautifulSoup(htmlText, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(soup), soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup.title\n",
    "dir(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The soup object allows you to retrieve specific types of tags, in this\n",
    "#     anchor tags (identified using an 'a'). Anchor tags are used for links.\n",
    "\n",
    "tags = soup('a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's cycle through the tags and get the 'href' data portion. this is the data that contains the link itself\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using documentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the documentation for a third party library.\n",
    "\n",
    "The documentation for Beautiful Soup has a number of nice attributes that can get you started fairly quickly, so let's use the documentation to enhance our knowledge of the subject.\n",
    "\n",
    "[Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "---\n",
    "\n",
    "## What is web scraping?\n",
    "\n",
    "Web scraping is a technique used to retrieve data from the web OR from similar networks (intranets, etc).\n",
    "\n",
    "* Web scrapers simulate the behavior of a browser\n",
    "* They look at the data from specific site(s)\n",
    "* They extract specific information you need from it\n",
    "* Typically this is done over and over again across multiple sites\n",
    "\n",
    "## Why web scrape?\n",
    "\n",
    "* Get data from a sites that don't provide mechanisms to export the data\n",
    "* Collect information on sites to build a search engine database\n",
    "* Monitor sites for changes\n",
    "* Collect social network data\n",
    "    * who is connected to or communicates with who?\n",
    "    * What is being said"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source:\n",
    "# http://www.jabberwocky.com/carroll/jabber/jabberwocky.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will run an HTTP server on your local computer...\n",
    "\n",
    "Run this from the command line.\n",
    "\n",
    "This allows you to test tools like Beautiful Soup even if you are not connected to the Internet.\n",
    "\n",
    "WARNING: **Do not use this web server in a production environment**, it is not fully evolved with hardened security settings, etc. It should be considered more of a testing/prototyping/experimental tool.\n",
    "\n",
    "```bash\n",
    "$ python -m http.server 8999 --bind 127.0.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = urllib.request.urlopen('http://localhost:8999/jabberwocky.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
