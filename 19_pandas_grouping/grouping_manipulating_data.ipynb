{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "Grouping/aggregating data\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Know how to group data by:\n",
    "    * Dictionary\n",
    "    * List\n",
    "    * Columns\n",
    "    * Index\n",
    "* Be able to aggregate data effectively\n",
    "* Make their own functions to use in aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame         #, Series\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby series\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a DataFrame that includes some sample data showing the messages (emails & tweets) received by diana and clark on each of two days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'name': ['diana', 'diana', 'clark', 'clark', 'diana'],\n",
    "                'msgs': ['email', 'tweet', 'email', 'tweet', 'email'],\n",
    "                'day1': [10, 11, 23, 23, 15],\n",
    "                'day2': [14, 15, 16, 17, 21]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data we can use the `.groupby()` method and section our columns based on what data they see that is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = df['day1'].groupby(df['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we have a `SeriesGroupBy` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores the data that lets us view our data group by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    for item in group:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our groups we can do vector math on groups individually (e.g. get every group's average or sum).\n",
    "\n",
    "Groupby objects already have a few methods attached to them that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get multilevel Groupby object we can have it group by *multiple* columns at once by giving the `.groupby()` method a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df['day1'].groupby( [df['name'], df['msgs']] ).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a multilevel Series-like object we can use the `.unstack()` method on it to display the object as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column you're going to use is in the same DataFrame as the original column you don't need to index to the column in the `.groupby()` method and instead you can just give it a string to use to grab the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['name', 'msgs']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to realize is that you don't actually need to use columns from the same DataFrame. You can use any array, series, or column that is the same length as your DataFrame or Series\n",
    "\n",
    "In this case we'll show you an example of using numpy arrays to group some of this data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = np.array(['new york', 'baltimore', 'baltimore', 'new york', 'new york'])\n",
    "day = np.array(['mon', 'mon', 'tues', 'mon', 'tues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day1'].groupby([cities, day]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another helpful groupby method is `.size()`. This method shows us how many objects fell into a given group. In this case it shows us that the clark group had 2 objects inside and the diana group had 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('name').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the same thing but we tell it to group by multiple columns. This time it shows us how many objects were in each subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['name', 'msgs']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try and iterate over a GroupBy object each loop will return a small tuple. This tuple contains the name of the group and secondarily the content in the group itself. Since it returns a tuple we can use tuple unpacking to get both the name and the group content alone in separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.groupby('msgs'):\n",
    "    if name == 'email':\n",
    "        print(name)\n",
    "        print('='*30)\n",
    "        print(group)\n",
    "        print()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this GroupBy object is multilevel each group combination has the \"name\" slot of that first tuple broken out into a new tuple with multiple parts for each level of the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k1, k2), group in df.groupby(['name', 'msgs']):\n",
    "    if k2 != 'tweet':\n",
    "        \n",
    "        print(k1, k2)\n",
    "        print('='*30)\n",
    "        print(group)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes (especially with larger datasets) grouping across the entire DataFrame might not be what you want to do. you can do column specific grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['name', 'msgs'])[['day2', 'day1']].mean()\n",
    "\n",
    "# The following line does the same thing, but displays multiple columns.\n",
    "# df.groupby(['key1', 'key2'])[['day1', 'day2']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are a number of other ways to implement grouping. One way is using\n",
    "# dictionaries to map columns (or rows) to values. In this case, we tie each\n",
    "# of the years to a grouping (pre vs post apocalyptic event and a third\n",
    "# category for future events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = DataFrame([[512, 613, 714, 815, 916],\n",
    "                    [413, 412, 411, 420, 415],\n",
    "                    [501, 525, 535, 545, 555],\n",
    "                    [501, 602, 545, 600, 599],\n",
    "                    [413, 603, 412, 599, 419]],\n",
    "                    columns=[2011, 2012, 2013, 2014, 2015],\n",
    "                    index=['clark', 'bruce', 'diana', 'kara', 'selina'])\n",
    "heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {2011: 'pre',\n",
    "           2012: 'pre',\n",
    "           2013: 'post',\n",
    "           2014: 'post',\n",
    "           2015: 'post',\n",
    "           2016: 'future'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So rather than grouping by a column, we simply drop in the dictionary:\n",
    "# in this case, we explicitly identify the grouping axis to be the columns\n",
    "# by using an axis=1 argument (the default is axis=0 for grouping by rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_column = heroes.groupby(mapping, axis=1)\n",
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: pre/post are lexigraphically sortable, and leads to all the 'post'\n",
    "# years being displayed infront of the 'pre' years, which seems weird, so\n",
    "# we tell the function to skip the alphabetical sorting process, which\n",
    "# leaves the 'pre' group (years 2011, 2012) in front of the 'post' group (years\n",
    "# 2013, 2014, 2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_column = heroes.groupby(mapping, axis=1, sort=False)\n",
    "by_column.describe()\n",
    "# by_dolumn.mean()\n",
    "# by_column.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can GroupBy the outputs of functions. it does not matter where the\n",
    "# function comes from, as long as it provides an output. For example, this\n",
    "# sample functions counts the number of vowels that show up in a superhero's\n",
    "# name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_vowels(name):\n",
    "    count = 0\n",
    "    for letter in name:\n",
    "        if letter in ['a', 'e', 'i', 'o', 'u']:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following will group the heroes based on the number of vowels in their\n",
    "# name (1, 2 or 3) and then will calculate the means of their emails by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.groupby(count_vowels).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What other aggregations can you do on data?\n",
    "# by_column.mean()\n",
    "# by_column.sum()\n",
    "# by_column.min()\n",
    "# by_column.max()\n",
    "# by_column.median()\n",
    "# by_column.first()\n",
    "# by_column.last()\n",
    "by_column.describe()\n",
    "\n",
    "# by_column.<tab>        # pressing the <tab> key in ipython after typing\n",
    "                         # \"by_column.' will display all the methods/attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is possible to apply any aggregation function to your data. for example\n",
    "# if we want to know how far off from the max, any given mean is, we can\n",
    "# calculate that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_mean_diff(arr):\n",
    "    return arr.max() - arr.mean()\n",
    "\n",
    "groups.agg(max_mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the next bit, let's look at a slightly more sophisticated dataset.\n",
    "# this is data that I generated randomly.\n",
    "# we start by reading in the data\n",
    "# then we perform a calculation to determine the relative pct between\n",
    "# the student's gpa and change in the gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas = pd.read_csv('../universal_datasets/gpa_short.csv')\n",
    "gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas['gpa_pct'] = gpas['gpa_change'] / gpas['gpa']\n",
    "gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from there, we group by the gender and the athlete statues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = gpas.groupby(['gender', 'athlete'])\n",
    "for grp in groups:\n",
    "    print(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then we pull out just the gpa_pct column in reference to the groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_pct = groups['gpa_pct']\n",
    "groups_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at this point we can apply some functions to this data. Notice the\n",
    "# use/non-use of quotes. for built-in functions, you need to use the\n",
    "# quotations. For funtions that you have defined in the current namespace\n",
    "# you can get away with not using the quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_pct.agg(['max', 'mean', max_mean_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are multiple ways to slice the data into columns that you want and\n",
    "# then aggregate the data in those columns. here is another method, where\n",
    "# we choose several columns and then apply four functions against each \n",
    "# of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = ['median', 'min', 'max', 'count']\n",
    "result = groups['gpa_pct', 'gpa'].agg(functions)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to focus on just a single grouping at a time, we can select\n",
    "# for that grouping via dictionary-like indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['gpa_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There is a way to map certain functions to only certain columns by using a dictionary to perform the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'gpa_change': 'min', 'duration': 'mean'}\n",
    "groups.agg(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This can get pretty sophisticated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2 = {'gpa_change': ['min', 'max', 'median'], 'duration': 'mean'}\n",
    "groups.agg(mapping2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sometimes, we want to perform aggregation, but we want to retain the\n",
    "# overall shape of the data, much like we did using the as_index=False argument\n",
    "# this is where the transform method comes in. Let's look at two attempts\n",
    "# to examine the mean for our heroes DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = ['cat_a', 'cat_b', 'cat_a', 'cat_b', 'cat_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "\n",
    "heroes.groupby(k).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "\n",
    "heroes.groupby(k).transform(max_mean_diff)\n",
    "\n",
    "# NOTE: as before, any function that can be applied to the group can be fed\n",
    "# into the transform function, for example:\n",
    "# heroes.groupby(k).transform(max_mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is another fundamental way to apply functions to the data in a Pandas\n",
    "# object: using apply()\n",
    "# let's say we want to find the best performers in terms of grade changes across\n",
    "# each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best(df, n=10, column='gpa_pct'):\n",
    "    return df.sort_values(by=column, ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we simply apply this to the gpas DataFrame, as a whole, we will see the\n",
    "# most improved students and their characteristics, here we use n=7 to get the\n",
    "# top seven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best(gpas, n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we use a GroupBy and then apply the function to the GroupBy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpas.groupby('athlete').apply(best)\n",
    "gpas.groupby('athlete').apply(best, n=2, column='gpa_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas.groupby(['athlete', 'gender']).apply(best, n=3)[['duration',\n",
    "                                                      'gpa_pct',\n",
    "                                                      'gpa_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfc = gpas[['gpa', 'gpa_change', 'gpa_pct']]\n",
    "gpabins = pd.cut(dfc.gpa_change, 10)\n",
    "gpabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_summary(grp):\n",
    "    return {'min': grp.min(),\n",
    "            'max': grp.max(),\n",
    "            'median': grp.median(),\n",
    "            'std': grp.std()}\n",
    "\n",
    "groups = dfc.gpa_pct.groupby(gpabins)\n",
    "# groups.apply(stat_summary)\n",
    "groups.apply(stat_summary).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
